# Analyse de Sentiments pour Air Paradis

Projet d'analyse de sentiment sur des tweets pour anticiper les potentiels bad buzz sur les r√©seaux sociaux. Ce projet impl√©mente trois approches de machine learning (mod√®le simple, mod√®le avanc√© TensorFlow/Keras, et BERT) avec une infrastructure MLOps compl√®te.

## Table des Mati√®res

- [Installation](#installation)
- [Configuration](#configuration)
- [Donn√©es](#donn√©es)
- [Utilisation](#utilisation)
  - [Entra√Ænement des mod√®les](#entra√Ænement-des-mod√®les)
  - [Interface MLflow](#interface-mlflow)
  - [API de pr√©diction](#api-de-pr√©diction)
- [Architecture](#architecture)
- [Tests](#tests)
- [D√©ploiement](#d√©ploiement)

## Installation

### Pr√©requis
- Python 3.12+
- Git
- Au moins 4GB de RAM pour les mod√®les BERT

### Installation rapide
```bash
# Cloner le projet
git clone <url-du-projet>
cd sentiment_analysis

# Cr√©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# ou
venv\Scripts\activate     # Sur Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

## Configuration

### 1. Donn√©es
Placez le dataset Sentiment140 dans le dossier `data/` :
```
data/
‚îú‚îÄ‚îÄ training.1600000.processed.noemoticon.csv  # Dataset principal
‚îî‚îÄ‚îÄ raw/                                       # Autres donn√©es brutes
```

### 2. MLflow
D√©marrez le serveur de tracking MLflow :
```bash
mlflow ui --host 0.0.0.0 --port 5001
```
Interface accessible sur : http://localhost:5001

## Donn√©es

Le projet utilise le dataset **Sentiment140** contenant 1,6M de tweets √©tiquet√©s :
- **0** : Sentiment n√©gatif
- **1** : Sentiment positif
- **Format** : CSV avec colonnes [sentiment, id, date, query, user, text]
- **R√©partition** : 50% n√©gatif, 50% positif (√©quilibr√©)

### Taille d'√©chantillon

**√âchantillon utilis√© pour ce projet :**
- **50 000 tweets** (apr√®s nettoyage : ~49 827 tweets)
- R√©partition √©quilibr√©e : 50% n√©gatif, 50% positif
- Vocabulaire couvert : ~10-11k mots uniques apr√®s pr√©traitement
- Consommation RAM : < 1GB (confortable pour d√©veloppement)

**Justification :**
- Suffisant pour benchmark et comparaison d'embeddings
- R√©sultats statistiquement stables (√©cart-type < 0.002)
- Temps d'entra√Ænement raisonnables (0.5s simple, 12-20min LSTM)
- Benchmarks ML standards utilisent 50k-400k √©chantillons (IMDB, Sentiment Treebank)

**Pour le mod√®le de production :**
- Augmenter √† 100k-400k tweets pour meilleure g√©n√©ralisation
- Dataset complet (1.6M) possible si ressources suffisantes

## Utilisation

### Entra√Ænement des mod√®les

#### Mod√®le Simple (Baseline)

**Entra√Æner avec une technique sp√©cifique :**
```bash
# Avec stemming
python train_simple_model.py --technique=stemming --description="Baseline stemming production"

# Avec lemmatization
python train_simple_model.py --technique=lemmatization --description="Baseline lemmatization"
```

**Comparer les techniques :**
```bash
# Comparaison compl√®te stemming vs lemmatization
python train_simple_model.py --technique=both --description="Comparaison techniques preprocessing"
```

**Options avanc√©es :**
```bash
# Avec √©chantillon r√©duit pour test rapide
python train_simple_model.py \
    --technique=lemmatization \
    --sample-size=50000 \
    --description="Test rapide lemmatization" \
    --experiment-name="tests_rapides"

# Dataset complet (par d√©faut)
python train_simple_model.py --technique=both --description="Entra√Ænement production"
```

#### Mod√®les Avanc√©s (TensorFlow/Keras + Embeddings)

**Word2Vec avec r√©seaux de neurones :**
```bash
# Word2Vec avec architecture Dense (embeddings moyenn√©s)
python train_word2vec_model.py --technique=stemming --sample-size=50000

# Word2Vec avec architecture LSTM (s√©quences)
python train_word2vec_model.py --technique=lemmatization --with-lstm --sample-size=50000

# Comparaison stemming vs lemmatization
python train_word2vec_model.py --technique=both --sample-size=50000 --description="Benchmark Word2Vec"

# Configuration avanc√©e
python train_word2vec_model.py \
    --technique=stemming \
    --with-lstm \
    --vector-size=200 \
    --sample-size=100000 \
    --description="Production Word2Vec LSTM"
```

**Autres embeddings (√† venir) :**
```bash
# FastText avec architecture LSTM
python train_fasttext_model.py --technique=lemmatization --with-lstm

# Universal Sentence Encoder (USE)
python train_use_model.py --technique=stemming

# BERT (fine-tuning)
python train_bert_model.py --technique=stemming --epochs=3
```

### Interface MLflow

1. **D√©marrer MLflow UI :**
   ```bash
   mlflow ui --host 0.0.0.0 --port 5001
   ```

2. **Naviguer dans l'interface :**
   - **Exp√©rimentations** : Organis√©es par type de mod√®le
   - **Runs** : Chaque entra√Ænement avec ses m√©triques
   - **Mod√®les** : Registre centralis√© des mod√®les
   - **Comparaison** : Comparer les performances visuellement

3. **Tags et filtres disponibles :**
   - `preprocessing_technique` : stemming, lemmatization
   - `model_category` : baseline, advanced, bert
   - `algorithm` : logistic_regression, lstm, bert
   - `description` : Description personnalis√©e

### API de pr√©diction

#### D√©marrer l'API locale
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Utiliser l'API
```bash
# Pr√©diction simple
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this product!"}'

# R√©ponse
{
  "sentiment": 1,
  "confidence": 0.87,
  "text": "I love this product!"
}
```

#### Interface de test Streamlit
```bash
streamlit run interface/app.py
```

## Architecture

### Structure du projet
```
sentiment_analysis/
‚îú‚îÄ‚îÄ api/                    # API FastAPI
‚îú‚îÄ‚îÄ data/                   # Datasets
‚îú‚îÄ‚îÄ models/                 # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/       # Checkpoints pour reprise d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ staging/           # Mod√®les en test
‚îÇ   ‚îî‚îÄ‚îÄ production/        # Mod√®les d√©ploy√©s
‚îú‚îÄ‚îÄ notebooks/             # Exploration de donn√©es
‚îú‚îÄ‚îÄ reports/               # Rapports d'√©valuation
‚îú‚îÄ‚îÄ src/                   # Code source
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/        # Impl√©mentations d'embeddings
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/        # M√©triques d'√©valuation
‚îÇ   ‚îú‚îÄ‚îÄ models/            # D√©finitions des mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/        # Outils de surveillance
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/     # Pr√©traitement des donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utilitaires (checkpoint manager, etc.)
‚îú‚îÄ‚îÄ tests/                 # Tests unitaires
‚îî‚îÄ‚îÄ mlruns/               # Donn√©es MLflow
```

### Pipeline MLOps
1. **D√©veloppement** : Notebooks d'exploration
2. **Entra√Ænement** : Scripts param√©tr√©s avec MLflow
3. **√âvaluation** : M√©triques automatiques et rapports
4. **Registre** : Mod√®les versionn√©s dans MLflow
5. **D√©ploiement** : API FastAPI sur cloud
6. **Surveillance** : Monitoring en production

## Tests

```bash
# Tests unitaires
python -m pytest tests/ -v

# Tests avec couverture
python -m pytest tests/ -v --cov=src --cov-report=html

# Tests de qualit√© de code
black src/ tests/ api/      # Formatage
flake8 src/ tests/ api/     # Linting
mypy src/ api/              # V√©rification de types
```

## D√©ploiement

### D√©ploiement local
```bash
# API en mode production
uvicorn api.main:app --host 0.0.0.0 --port 8000

# Avec Docker (√† configurer)
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```

### D√©ploiement cloud (AWS)
```bash
# Configuration √† venir
# - AWS EC2 ou Lambda
# - Pipeline CI/CD avec GitHub Actions
# - Monitoring CloudWatch
```

## M√©triques et Monitoring

### M√©triques d'√©valuation
- **Accuracy** : Taux de bonnes classifications
- **F1-Score** : Mesure √©quilibr√©e (m√©trique principale)
- **Pr√©cision/Rappel** : Performance par classe
- **AUC-ROC** : Capacit√© de discrimination
- **Temps d'entra√Ænement** : Performance op√©rationnelle

## R√©sultats des Exp√©rimentations

### üìä Mod√®les Simples - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `simple_models_50000_v1` - Analyse comparative Stemming vs Lemmatization
**Dataset** : 50 000 tweets Sentiment140
**Algorithme** : Logistic Regression + TF-IDF
**Date** : Octobre 2025

#### üèÜ Meilleur Mod√®le

**Configuration gagnante** : Stemming + N√©gations=True + √âmotions=True

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7754** |
| **Accuracy** | **0.7754** |
| **AUC-ROC** | **0.8569** |
| **Pr√©cision** | 0.7754 |
| **Rappel** | 0.7754 |
| **Temps d'entra√Ænement** | 0.49s |

#### üìà Comparaison Stemming vs Lemmatization

| Configuration | Stemming | Lemmatization | Œî (Stemming - Lemma) |
|---------------|----------|---------------|----------------------|
| **N√©gations + √âmotions** | **0.7754** (AUC: 0.8569) | 0.7722 (AUC: 0.8559) | **+0.0032** |
| **N√©gations seules** | **0.7743** (AUC: 0.8577) | 0.7715 (AUC: 0.8554) | **+0.0028** |
| **√âmotions seules** | **0.7712** (AUC: 0.8534) | 0.7706 (AUC: 0.8528) | **+0.0006** |
| **Sans gestion** | **0.7739** (AUC: 0.8534) | 0.7710 (AUC: 0.8517) | **+0.0029** |

#### üìä Statistiques Globales

| M√©trique | Valeur |
|----------|--------|
| **Accuracy moyenne** | 0.7725 |
| **√âcart-type (std)** | 0.0018 |
| **F1-Score moyen** | 0.7725 |
| **√âcart-type (std)** | 0.0018 |

#### üí° Observations Cl√©s

1. **Stemming syst√©matiquement meilleur** : Performance sup√©rieure dans toutes les configurations (+0.28% √† +0.32%)
2. **N√©gations + √âmotions = optimal** : Meilleure configuration avec F1=0.7754 et AUC=0.8569
3. **Stabilit√© remarquable** : √âcart-type tr√®s faible (0.0018) ‚Üí r√©sultats reproductibles
4. **Temps d'entra√Ænement** : Stemming (0.43-0.49s) ~15% plus rapide que lemmatization (0.49-0.60s)
5. **AUC-ROC √©lev√©e** : 0.85+ sur tous les mod√®les ‚Üí excellente capacit√© de discrimination

#### üéØ Recommandations

- **Production** : Stemming + N√©gations=True + √âmotions=True
- **Justification** : Meilleur compromis performance/rapidit√©
- **Gain vs baseline** : +0.32% vs lemmatization sur configuration √©quivalente
- **Robustesse** : Variance minimale entre runs (std=0.0018)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_simple_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_simple_models_50000_v1_*.csv`
- MLflow UI : http://localhost:5001 (exp√©rience: `simple_models_50000_v1`)

---

### üìä Mod√®les Word2Vec - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `word2vec_models_50000_v1` - Word2Vec + R√©seaux de neurones
**Dataset** : 49 827 tweets Sentiment140 (apr√®s nettoyage)
**Algorithme** : Word2Vec (Skip-gram, 100 dim) + Dense/LSTM
**Date** : Octobre 2025

#### üèÜ Meilleur Mod√®le

**Configuration gagnante** : Word2Vec + Stemming + LSTM

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7653** |
| **Accuracy** | **0.7654** |
| **AUC-ROC** | **0.8472** |
| **Pr√©cision** | 0.7658 |
| **Rappel** | 0.7654 |
| **Epochs entra√Æn√©s** | 13/30 (early stopping) |
| **Vocabulaire** | 9 970 mots |
| **Temps d'entra√Ænement** | 701.8s (~11.7 min) |

#### üìà Comparaison Architectures

**Dense (Embeddings moyenn√©s) :**

| Technique | F1-Score | AUC-ROC | Temps moyen | Epochs moyen |
|-----------|----------|---------|-------------|--------------|
| **Stemming** | **0.7571** (¬±0.0004) | **0.8364** | 19.1s | 19.7 |
| **Lemmatization** | **0.7526** (¬±0.0009) | **0.8331** | 18.1s | 18.3 |
| **Œî (Stem - Lemma)** | **+0.0045** | **+0.0033** | +1.0s | +1.4 |

**LSTM (S√©quences de vecteurs) :**

| Technique | F1-Score | AUC-ROC | Temps | Epochs |
|-----------|----------|---------|-------|--------|
| **Stemming** | **0.7653** | **0.8472** | 701.8s | 13 |
| **Lemmatization** | **0.7609** | **0.8435** | 643.7s | 12 |
| **Œî (Stem - Lemma)** | **+0.0044** | **+0.0037** | +58.1s | +1 |

#### üí° Observations Cl√©s

1. **LSTM surpasse Dense** : +0.9% F1-Score, +1.1% AUC-ROC
2. **Stemming syst√©matiquement meilleur** : +0.45% (Dense) et +0.44% (LSTM) vs lemmatization
3. **Trade-off performance/temps** : LSTM 38x plus lent que Dense pour +0.9% de gain
4. **Vocabulaire plus compact** : Stemming (9 970 mots) vs Lemmatization (11 353 mots) = -12%
5. **Early stopping efficace** : Arr√™t √† 12-13 epochs au lieu de 30 (gain de temps √ó2.3)
6. **Stabilit√© Dense remarquable** : √âcart-type tr√®s faible (0.0004-0.0009) ‚Üí r√©sultats reproductibles

#### üìä Comparaison avec Mod√®le Simple

| Mod√®le | F1-Score | AUC-ROC | Temps | Ratio Perf/Temps |
|--------|----------|---------|-------|------------------|
| **Simple (Logistic + TF-IDF)** | **0.7754** | **0.8569** | **0.49s** | **1.58 F1/s** |
| **Word2Vec + Dense** | 0.7571 | 0.8364 | 19.1s | 0.040 F1/s |
| **Word2Vec + LSTM** | 0.7653 | 0.8472 | 701.8s | 0.001 F1/s |

**√âcart de performance** :
- Simple vs W2V+Dense : **+1.8% F1, +2.0% AUC** (39x plus rapide)
- Simple vs W2V+LSTM : **+1.0% F1, +1.0% AUC** (1432x plus rapide)

#### üéØ Recommandations

**Pour ce projet** :
- ‚ùå **Ne pas utiliser Word2Vec seul** : Performance inf√©rieure au mod√®le simple baseline
- ‚úÖ **Tester d'autres embeddings** : FastText, USE, BERT pour surpasser le baseline
- ‚ö†Ô∏è **LSTM co√ªt/b√©n√©fice faible** : +0.9% pour 38x plus de temps vs Dense

**Prochaines √©tapes** :
1. **Universal Sentence Encoder (USE)** : Embeddings de documents pr√©-entra√Æn√©s state-of-the-art
2. **BERT fine-tun√©** : Mod√®le transformer pour NLP (meilleure performance attendue)
3. **FastText** : Gestion des mots hors vocabulaire et sous-mots

**Si Word2Vec n√©cessaire** :
- Configuration optimale : Stemming + LSTM (F1=0.7653)
- Alternative rapide : Stemming + Dense (F1=0.7571, 19s)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_word2vec_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_word2vec_models_50000_v1_*.csv`
- Courbes d'entra√Ænement : Disponibles dans MLflow artifacts (training_curves/)
- MLflow UI : http://localhost:5001 (exp√©rience: `word2vec_models_50000_v1`)

---

### üìä Mod√®les FastText - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `fasttext_models_50000_v1` - FastText + R√©seaux de neurones
**Dataset** : 49 827 tweets Sentiment140 (apr√®s nettoyage)
**Algorithme** : FastText (Skip-gram, 100 dim, n-grammes 3-6) + Dense/LSTM
**Date** : Octobre 2025

#### üèÜ Meilleur Mod√®le

**Configuration gagnante** : FastText + Stemming + LSTM

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7628** |
| **Accuracy** | **0.7631** |
| **AUC-ROC** | **0.8454** |
| **Pr√©cision** | 0.7641 |
| **Rappel** | 0.7631 |
| **Epochs entra√Æn√©s** | 12/30 (early stopping) |
| **Vocabulaire** | 9 970 mots |
| **Temps d'entra√Ænement** | 659.0s (~11 min) |

#### üìà Comparaison FastText vs Word2Vec

**Architecture Dense (Embeddings moyenn√©s) :**

| Embedding | F1-Score | AUC-ROC | Temps | Epochs | Œî (FT - W2V) |
|-----------|----------|---------|-------|--------|--------------|
| **FastText** | 0.7551 | 0.8337 | 29.1s | 28 | **+0.10%** |
| Word2Vec | 0.7541 | 0.8340 | 18.7s | 19 | - |

**Architecture LSTM (S√©quences de vecteurs) :**

| Embedding | F1-Score | AUC-ROC | Temps | Epochs | Œî (FT - W2V) |
|-----------|----------|---------|-------|--------|--------------|
| **Word2Vec** | **0.7657** | **0.8463** | 659.8s | 12 | - |
| FastText | 0.7628 | 0.8454 | 659.0s | 12 | **-0.29%** |

#### üí° Observations Cl√©s

1. **Word2Vec l√©g√®rement meilleur sur LSTM** : +0.29% F1 (meilleur mod√®le global)
2. **FastText l√©g√®rement meilleur sur Dense** : +0.10% F1, mais 55% plus lent (calcul n-grammes)
3. **LSTM > Dense** : +0.8% F1 pour FastText (vs +0.9% pour Word2Vec)
4. **Avantage th√©orique FastText non confirm√©** : Gestion OOV via n-grammes n'am√©liore pas les performances
5. **Hypoth√®se** : Dataset Sentiment140 bien form√©, peu de typos ou mots hors vocabulaire
6. **Early stopping efficace** : Arr√™t √† 12 epochs au lieu de 30 pour LSTM

#### üìä Comparaison avec Mod√®le Simple

| Mod√®le | F1-Score | AUC-ROC | Temps | Ratio Perf/Temps |
|--------|----------|---------|-------|------------------|
| **Simple (Logistic + TF-IDF)** | **0.7754** | **0.8569** | **0.49s** | **1.58 F1/s** |
| Word2Vec + LSTM | 0.7657 | 0.8463 | 659.8s | 0.001 F1/s |
| **FastText + LSTM** | 0.7628 | 0.8454 | 659.0s | 0.001 F1/s |
| FastText + Dense | 0.7551 | 0.8337 | 29.1s | 0.026 F1/s |

**√âcart de performance** :
- Simple vs FastText+LSTM : **+1.3% F1, +1.2% AUC** (1345x plus rapide)
- Simple vs FastText+Dense : **+2.0% F1, +2.3% AUC** (59x plus rapide)

#### üéØ Analyse et Recommandations

**Pourquoi TF-IDF surpasse Word2Vec/FastText ?**
1. **Corpus trop petit** : 50k tweets insuffisants pour entra√Æner des embeddings de qualit√© (besoin de millions)
2. **Tweets = textes courts** : Sentiment port√© par mots-cl√©s forts ‚Üí TF-IDF capture parfaitement
3. **Word2Vec/FastText from scratch** : Embeddings sous-optimaux sans transfer learning
4. **Ratio param√®tres/donn√©es** : Mod√®les neuronaux (50-500k param√®tres) sur 50k samples ‚Üí risque overfitting

**Pour ce projet** :
- ‚ùå **Ne pas utiliser FastText seul** : Pas d'am√©lioration vs Word2Vec, sous-performe le baseline
- ‚úÖ **Tester embeddings pr√©-entra√Æn√©s** : USE ou BERT pour transfer learning
- üìö **R√©sultat coh√©rent avec la litt√©rature** : TF-IDF bat embeddings from scratch sur petits corpus

**Prochaines √©tapes** :
1. **Universal Sentence Encoder (USE)** : Embeddings pr√©-entra√Æn√©s sentence-level (attendu : ~78-80% F1)
2. **BERT fine-tun√©** : Transfer learning sur transformer (meilleure performance attendue)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_fasttext_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_fasttext_models_50000_v1_*.csv`
- Courbes d'entra√Ænement : Disponibles dans MLflow artifacts (training_curves/)
- MLflow UI : http://localhost:5001 (exp√©rience: `fasttext_models_50000_v1`)

---

### üìä Mod√®les USE - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `use_models_50000_v1` - Universal Sentence Encoder + Dense
**Dataset** : 49 827 tweets Sentiment140 (apr√®s nettoyage)
**Algorithme** : USE pr√©-entra√Æn√© (512 dim, sentence-level) + Dense
**Date** : Octobre 2025

#### üèÜ R√©sultat (Stemming uniquement)

**Configuration test√©e** : USE + Stemming + Dense

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7421** |
| **Accuracy** | **0.7423** |
| **AUC-ROC** | **0.8218** |
| **Pr√©cision** | 0.7432 |
| **Rappel** | 0.7423 |
| **Epochs entra√Æn√©s** | 8/30 (early stopping) |
| **Temps d'entra√Ænement** | 77.4s |

‚ö†Ô∏è **Note** : Exp√©rience incompl√®te, seule la technique stemming a √©t√© test√©e (lemmatization manquante).

#### üìà Comparaison avec tous les mod√®les

**Classement g√©n√©ral (F1-Score) :**

| Rang | Mod√®le | F1-Score | AUC-ROC | Temps | Œî vs Baseline |
|------|--------|----------|---------|-------|---------------|
| 1Ô∏è‚É£ | **Simple (Logistic + TF-IDF)** | **0.7754** | **0.8569** | **0.49s** | - |
| 2Ô∏è‚É£ | Word2Vec + LSTM | 0.7657 | 0.8463 | 659.8s | -1.0% |
| 3Ô∏è‚É£ | FastText + LSTM | 0.7628 | 0.8454 | 659.0s | -1.3% |
| 4Ô∏è‚É£ | Word2Vec + Dense | 0.7571 | 0.8364 | 19.1s | -1.8% |
| 5Ô∏è‚É£ | FastText + Dense | 0.7551 | 0.8337 | 29.1s | -2.0% |
| 6Ô∏è‚É£ | **USE + Dense** | **0.7421** | **0.8218** | **77.4s** | **-3.3%** |

#### üí° Observations Cl√©s

1. **USE sous-performe TOUS les autres mod√®les** : F1=0.7421 (pire r√©sultat du benchmark)
2. **-3.3% en dessous du baseline simple** : 33 points de moins que TF-IDF
3. **Early stopping tr√®s pr√©coce** : Arr√™t √† 8 epochs (vs 12-19 pour Word2Vec/FastText)
4. **Temps d'entra√Ænement √©lev√©** : 77s pour chargement USE + entra√Ænement (158x plus lent que baseline)
5. **AUC-ROC la plus faible** : 0.8218 (vs 0.8569 pour baseline, -35 points)

#### üîç Analyse : Pourquoi USE sous-performe ?

**Hypoth√®ses expliquant les mauvaises performances :**

1. **USE optimis√© pour similarit√© s√©mantique** :
   - Con√ßu pour mesurer la similarit√© entre phrases, pas pour classification de sentiment
   - Perd les mots-cl√©s discriminants forts ("love", "hate") dans l'encodage global

2. **Tweets trop courts pour USE** :
   - USE excelle sur phrases longues avec contexte riche (20-30 mots)
   - Tweets : 10-15 mots en moyenne ‚Üí contexte insuffisant
   - TF-IDF capture mieux les mots-cl√©s dans textes courts

3. **Architecture trop simple** :
   - Une seule couche Dense au-dessus de USE (512 ‚Üí 1)
   - Pas assez de capacit√© pour adapter les embeddings √† la t√¢che

4. **Early stopping trop pr√©coce** :
   - Arr√™t √† 8 epochs (sous-entra√Ænement possible)
   - Mod√®le n'a pas eu le temps de converger correctement

5. **Embeddings fig√©s** :
   - USE pr√©-entra√Æn√© non fine-tun√© sur sentiment
   - Encodage g√©n√©rique pas adapt√© √† la t√¢che sp√©cifique

#### üéØ Enseignements et Recommandations

**Ce que ce benchmark d√©montre :**
- ‚úÖ **TF-IDF reste champion** : Simplicit√© et efficacit√© battent la complexit√©
- ‚úÖ **Transfer learning ‚â† garantie de succ√®s** : Embeddings pr√©-entra√Æn√©s pas toujours meilleurs
- ‚úÖ **Textes courts = mots-cl√©s > contexte** : USE perd face √† approches lexicales
- ‚ùå **USE inadapt√© pour tweets** : Con√ßu pour phrases longues et riches en contexte

**Recommandations :**
- ‚ùå **Ne pas utiliser USE pour sentiment Twitter** : Sous-performe m√™me les embeddings from scratch
- ‚úÖ **Conserver TF-IDF comme baseline production** : Meilleur rapport performance/complexit√©
- üî¨ **Tester BERT fine-tun√©** : Derni√®re chance pour les embeddings pr√©-entra√Æn√©s
  - BERT peut √™tre fine-tun√© (contrairement √† USE fig√©)
  - BERT-base con√ßu pour classification (USE pour similarit√©)

**Prochaine √©tape** :
- **BERT fine-tuning** : Entra√Æner les derni√®res couches sur sentiment Twitter
- Si BERT < TF-IDF ‚Üí **Utiliser TF-IDF en production** (plus simple, plus rapide, meilleur)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_use_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_use_models_50000_v1_*.csv`
- Courbes d'entra√Ænement : Disponibles dans MLflow artifacts (training_curves/)
- MLflow UI : http://localhost:5001 (exp√©rience: `use_models_50000_v1`)

---

### Surveillance en production
- **Seuil d'alerte** : 3 pr√©dictions incorrectes en 5 minutes
- **Monitoring** : AWS CloudWatch
- **Alertes** : Email/SMS automatiques
- **Drift detection** : Surveillance de la qualit√© des pr√©dictions

## Contribution

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -m 'Ajout nouvelle fonctionnalit√©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Cr√©er une Pull Request

## License

Ce projet est d√©velopp√© dans le cadre de la formation OpenClassrooms AI Engineer.

## Support

Pour toute question ou probl√®me :
1. Consulter la documentation dans `/docs`
2. V√©rifier les issues existantes
3. Cr√©er une nouvelle issue avec le template appropri√©

---

**Statut du projet** : En d√©veloppement actif
**Derni√®re mise √† jour** : Voir les commits r√©cents
