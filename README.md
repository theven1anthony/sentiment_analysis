# Analyse de Sentiments pour Air Paradis

Projet d'analyse de sentiment sur des tweets pour anticiper les potentiels bad buzz sur les r√©seaux sociaux. Ce projet impl√©mente trois approches de machine learning (mod√®le simple, mod√®le avanc√© TensorFlow/Keras, et BERT) avec une infrastructure MLOps compl√®te.

## Table des Mati√®res

- [Installation](#installation)
- [Configuration](#configuration)
- [Donn√©es](#donn√©es)
- [Utilisation](#utilisation)
  - [Entra√Ænement des mod√®les](#entra√Ænement-des-mod√®les)
  - [Interface MLflow](#interface-mlflow)
  - [API de pr√©diction](#api-de-pr√©diction)
- [Architecture](#architecture)
- [Tests](#tests)
- [D√©ploiement](#d√©ploiement)

## Installation

### Pr√©requis
- Python 3.12+
- Git
- Au moins 4GB de RAM pour les mod√®les BERT

### Installation rapide
```bash
# Cloner le projet
git clone <url-du-projet>
cd sentiment_analysis

# Cr√©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# ou
venv\Scripts\activate     # Sur Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

## Configuration

### 1. Donn√©es
Placez le dataset Sentiment140 dans le dossier `data/` :
```
data/
‚îú‚îÄ‚îÄ training.1600000.processed.noemoticon.csv  # Dataset principal
‚îî‚îÄ‚îÄ raw/                                       # Autres donn√©es brutes
```

### 2. MLflow
D√©marrez le serveur de tracking MLflow :
```bash
mlflow ui --host 0.0.0.0 --port 5001
```
Interface accessible sur : http://localhost:5001

## Donn√©es

Le projet utilise le dataset **Sentiment140** contenant 1,6M de tweets √©tiquet√©s :
- **0** : Sentiment n√©gatif
- **1** : Sentiment positif
- **Format** : CSV avec colonnes [sentiment, id, date, query, user, text]
- **R√©partition** : 50% n√©gatif, 50% positif (√©quilibr√©)

### Taille d'√©chantillon

**√âchantillon utilis√© pour ce projet :**
- **50 000 tweets** (apr√®s nettoyage : ~49 827 tweets)
- R√©partition √©quilibr√©e : 50% n√©gatif, 50% positif
- Vocabulaire couvert : ~10-11k mots uniques apr√®s pr√©traitement
- Consommation RAM : < 1GB (confortable pour d√©veloppement)

**Justification :**
- Suffisant pour benchmark et comparaison d'embeddings
- R√©sultats statistiquement stables (√©cart-type < 0.002)
- Temps d'entra√Ænement raisonnables (0.5s simple, 12-20min LSTM)
- Benchmarks ML standards utilisent 50k-400k √©chantillons (IMDB, Sentiment Treebank)

**Pour le mod√®le de production :**
- Augmenter √† 100k-400k tweets pour meilleure g√©n√©ralisation
- Dataset complet (1.6M) possible si ressources suffisantes

## Utilisation

### Entra√Ænement des mod√®les

#### Mod√®le Simple (Baseline)

**Entra√Æner avec une technique sp√©cifique :**
```bash
# Avec stemming
python train_simple_model.py --technique=stemming --description="Baseline stemming production"

# Avec lemmatization
python train_simple_model.py --technique=lemmatization --description="Baseline lemmatization"
```

**Comparer les techniques :**
```bash
# Comparaison compl√®te stemming vs lemmatization
python train_simple_model.py --technique=both --description="Comparaison techniques preprocessing"
```

**Options avanc√©es :**
```bash
# Avec √©chantillon r√©duit pour test rapide
python train_simple_model.py \
    --technique=lemmatization \
    --sample-size=50000 \
    --description="Test rapide lemmatization" \
    --experiment-name="tests_rapides"

# Dataset complet (par d√©faut)
python train_simple_model.py --technique=both --description="Entra√Ænement production"
```

#### Mod√®les Avanc√©s (TensorFlow/Keras + Embeddings)

**Word2Vec avec r√©seaux de neurones :**
```bash
# Word2Vec avec architecture Dense (embeddings moyenn√©s)
python train_word2vec_model.py --technique=stemming --sample-size=50000

# Word2Vec avec architecture LSTM (s√©quences)
python train_word2vec_model.py --technique=lemmatization --with-lstm --sample-size=50000

# Comparaison stemming vs lemmatization
python train_word2vec_model.py --technique=both --sample-size=50000 --description="Benchmark Word2Vec"

# Configuration avanc√©e
python train_word2vec_model.py \
    --technique=stemming \
    --with-lstm \
    --vector-size=200 \
    --sample-size=100000 \
    --description="Production Word2Vec LSTM"
```

**Autres embeddings (√† venir) :**
```bash
# FastText avec architecture LSTM
python train_fasttext_model.py --technique=lemmatization --with-lstm

# Universal Sentence Encoder (USE)
python train_use_model.py --technique=stemming

# BERT (fine-tuning)
python train_bert_model.py --technique=stemming --epochs=3
```

### Interface MLflow

1. **D√©marrer MLflow UI :**
   ```bash
   mlflow ui --host 0.0.0.0 --port 5001
   ```

2. **Naviguer dans l'interface :**
   - **Exp√©rimentations** : Organis√©es par type de mod√®le
   - **Runs** : Chaque entra√Ænement avec ses m√©triques
   - **Mod√®les** : Registre centralis√© des mod√®les
   - **Comparaison** : Comparer les performances visuellement

3. **Tags et filtres disponibles :**
   - `preprocessing_technique` : stemming, lemmatization
   - `model_category` : baseline, advanced, bert
   - `algorithm` : logistic_regression, lstm, bert
   - `description` : Description personnalis√©e

### API de pr√©diction

#### D√©marrer l'API locale
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Utiliser l'API
```bash
# Pr√©diction simple
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this product!"}'

# R√©ponse
{
  "sentiment": 1,
  "confidence": 0.87,
  "text": "I love this product!"
}
```

#### Interface de test Streamlit
```bash
streamlit run interface/app.py
```

## Architecture

### Structure du projet
```
sentiment_analysis/
‚îú‚îÄ‚îÄ api/                    # API FastAPI
‚îú‚îÄ‚îÄ data/                   # Datasets
‚îú‚îÄ‚îÄ models/                 # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/       # Checkpoints pour reprise d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ staging/           # Mod√®les en test
‚îÇ   ‚îî‚îÄ‚îÄ production/        # Mod√®les d√©ploy√©s
‚îú‚îÄ‚îÄ notebooks/             # Exploration de donn√©es
‚îú‚îÄ‚îÄ reports/               # Rapports d'√©valuation
‚îú‚îÄ‚îÄ src/                   # Code source
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/        # Impl√©mentations d'embeddings
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/        # M√©triques d'√©valuation
‚îÇ   ‚îú‚îÄ‚îÄ models/            # D√©finitions des mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/        # Outils de surveillance
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/     # Pr√©traitement des donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utilitaires (checkpoint manager, etc.)
‚îú‚îÄ‚îÄ tests/                 # Tests unitaires
‚îî‚îÄ‚îÄ mlruns/               # Donn√©es MLflow
```

### Pipeline MLOps
1. **D√©veloppement** : Notebooks d'exploration
2. **Entra√Ænement** : Scripts param√©tr√©s avec MLflow
3. **√âvaluation** : M√©triques automatiques et rapports
4. **Registre** : Mod√®les versionn√©s dans MLflow
5. **D√©ploiement** : API FastAPI sur cloud
6. **Surveillance** : Monitoring en production

## Tests

```bash
# Tests unitaires
python -m pytest tests/ -v

# Tests avec couverture
python -m pytest tests/ -v --cov=src --cov-report=html

# Tests de qualit√© de code
black src/ tests/ api/      # Formatage
flake8 src/ tests/ api/     # Linting
mypy src/ api/              # V√©rification de types
```

## D√©ploiement

### D√©ploiement local
```bash
# API en mode production
uvicorn api.main:app --host 0.0.0.0 --port 8000

# Avec Docker (√† configurer)
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```

### D√©ploiement cloud (AWS)
```bash
# Configuration √† venir
# - AWS EC2 ou Lambda
# - Pipeline CI/CD avec GitHub Actions
# - Monitoring CloudWatch
```

## M√©triques et Monitoring

### M√©triques d'√©valuation
- **Accuracy** : Taux de bonnes classifications
- **F1-Score** : Mesure √©quilibr√©e (m√©trique principale)
- **Pr√©cision/Rappel** : Performance par classe
- **AUC-ROC** : Capacit√© de discrimination
- **Temps d'entra√Ænement** : Performance op√©rationnelle

## R√©sultats des Exp√©rimentations

### üìä Mod√®les Simples - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `simple_models_50000_v1` - Analyse comparative Stemming vs Lemmatization
**Dataset** : 50 000 tweets Sentiment140
**Algorithme** : Logistic Regression + TF-IDF
**Date** : Octobre 2025

#### üèÜ Meilleur Mod√®le

**Configuration gagnante** : Stemming + N√©gations=True + √âmotions=True

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7754** |
| **Accuracy** | **0.7754** |
| **AUC-ROC** | **0.8569** |
| **Pr√©cision** | 0.7754 |
| **Rappel** | 0.7754 |
| **Temps d'entra√Ænement** | 0.49s |

#### üìà Comparaison Stemming vs Lemmatization

| Configuration | Stemming | Lemmatization | Œî (Stemming - Lemma) |
|---------------|----------|---------------|----------------------|
| **N√©gations + √âmotions** | **0.7754** (AUC: 0.8569) | 0.7722 (AUC: 0.8559) | **+0.0032** |
| **N√©gations seules** | **0.7743** (AUC: 0.8577) | 0.7715 (AUC: 0.8554) | **+0.0028** |
| **√âmotions seules** | **0.7712** (AUC: 0.8534) | 0.7706 (AUC: 0.8528) | **+0.0006** |
| **Sans gestion** | **0.7739** (AUC: 0.8534) | 0.7710 (AUC: 0.8517) | **+0.0029** |

#### üìä Statistiques Globales

| M√©trique | Valeur |
|----------|--------|
| **Accuracy moyenne** | 0.7725 |
| **√âcart-type (std)** | 0.0018 |
| **F1-Score moyen** | 0.7725 |
| **√âcart-type (std)** | 0.0018 |

#### üí° Observations Cl√©s

1. **Stemming syst√©matiquement meilleur** : Performance sup√©rieure dans toutes les configurations (+0.28% √† +0.32%)
2. **N√©gations + √âmotions = optimal** : Meilleure configuration avec F1=0.7754 et AUC=0.8569
3. **Stabilit√© remarquable** : √âcart-type tr√®s faible (0.0018) ‚Üí r√©sultats reproductibles
4. **Temps d'entra√Ænement** : Stemming (0.43-0.49s) ~15% plus rapide que lemmatization (0.49-0.60s)
5. **AUC-ROC √©lev√©e** : 0.85+ sur tous les mod√®les ‚Üí excellente capacit√© de discrimination

#### üéØ Recommandations

- **Production** : Stemming + N√©gations=True + √âmotions=True
- **Justification** : Meilleur compromis performance/rapidit√©
- **Gain vs baseline** : +0.32% vs lemmatization sur configuration √©quivalente
- **Robustesse** : Variance minimale entre runs (std=0.0018)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_simple_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_simple_models_50000_v1_*.csv`
- MLflow UI : http://localhost:5001 (exp√©rience: `simple_models_50000_v1`)

---

### üìä Mod√®les Word2Vec - Benchmark sur 50 000 Tweets

**Exp√©rimentation** : `word2vec_models_50000_v1` - Word2Vec + R√©seaux de neurones
**Dataset** : 49 827 tweets Sentiment140 (apr√®s nettoyage)
**Algorithme** : Word2Vec (Skip-gram, 100 dim) + Dense/LSTM
**Date** : Octobre 2025

#### üèÜ Meilleur Mod√®le

**Configuration gagnante** : Word2Vec + Stemming + LSTM

| M√©trique | Valeur |
|----------|--------|
| **F1-Score** | **0.7653** |
| **Accuracy** | **0.7654** |
| **AUC-ROC** | **0.8472** |
| **Pr√©cision** | 0.7658 |
| **Rappel** | 0.7654 |
| **Epochs entra√Æn√©s** | 13/30 (early stopping) |
| **Vocabulaire** | 9 970 mots |
| **Temps d'entra√Ænement** | 701.8s (~11.7 min) |

#### üìà Comparaison Architectures

**Dense (Embeddings moyenn√©s) :**

| Technique | F1-Score | AUC-ROC | Temps moyen | Epochs moyen |
|-----------|----------|---------|-------------|--------------|
| **Stemming** | **0.7571** (¬±0.0004) | **0.8364** | 19.1s | 19.7 |
| **Lemmatization** | **0.7526** (¬±0.0009) | **0.8331** | 18.1s | 18.3 |
| **Œî (Stem - Lemma)** | **+0.0045** | **+0.0033** | +1.0s | +1.4 |

**LSTM (S√©quences de vecteurs) :**

| Technique | F1-Score | AUC-ROC | Temps | Epochs |
|-----------|----------|---------|-------|--------|
| **Stemming** | **0.7653** | **0.8472** | 701.8s | 13 |
| **Lemmatization** | **0.7609** | **0.8435** | 643.7s | 12 |
| **Œî (Stem - Lemma)** | **+0.0044** | **+0.0037** | +58.1s | +1 |

#### üí° Observations Cl√©s

1. **LSTM surpasse Dense** : +0.9% F1-Score, +1.1% AUC-ROC
2. **Stemming syst√©matiquement meilleur** : +0.45% (Dense) et +0.44% (LSTM) vs lemmatization
3. **Trade-off performance/temps** : LSTM 38x plus lent que Dense pour +0.9% de gain
4. **Vocabulaire plus compact** : Stemming (9 970 mots) vs Lemmatization (11 353 mots) = -12%
5. **Early stopping efficace** : Arr√™t √† 12-13 epochs au lieu de 30 (gain de temps √ó2.3)
6. **Stabilit√© Dense remarquable** : √âcart-type tr√®s faible (0.0004-0.0009) ‚Üí r√©sultats reproductibles

#### üìä Comparaison avec Mod√®le Simple

| Mod√®le | F1-Score | AUC-ROC | Temps | Ratio Perf/Temps |
|--------|----------|---------|-------|------------------|
| **Simple (Logistic + TF-IDF)** | **0.7754** | **0.8569** | **0.49s** | **1.58 F1/s** |
| **Word2Vec + Dense** | 0.7571 | 0.8364 | 19.1s | 0.040 F1/s |
| **Word2Vec + LSTM** | 0.7653 | 0.8472 | 701.8s | 0.001 F1/s |

**√âcart de performance** :
- Simple vs W2V+Dense : **+1.8% F1, +2.0% AUC** (39x plus rapide)
- Simple vs W2V+LSTM : **+1.0% F1, +1.0% AUC** (1432x plus rapide)

#### üéØ Recommandations

**Pour ce projet** :
- ‚ùå **Ne pas utiliser Word2Vec seul** : Performance inf√©rieure au mod√®le simple baseline
- ‚úÖ **Tester d'autres embeddings** : FastText, USE, BERT pour surpasser le baseline
- ‚ö†Ô∏è **LSTM co√ªt/b√©n√©fice faible** : +0.9% pour 38x plus de temps vs Dense

**Prochaines √©tapes** :
1. **Universal Sentence Encoder (USE)** : Embeddings de documents pr√©-entra√Æn√©s state-of-the-art
2. **BERT fine-tun√©** : Mod√®le transformer pour NLP (meilleure performance attendue)
3. **FastText** : Gestion des mots hors vocabulaire et sous-mots

**Si Word2Vec n√©cessaire** :
- Configuration optimale : Stemming + LSTM (F1=0.7653)
- Alternative rapide : Stemming + Dense (F1=0.7571, 19s)

#### üìÅ Rapports Complets

- Rapport d√©taill√© : `reports/mlflow_report_word2vec_models_50000_v1_*.txt`
- Donn√©es brutes : `reports/mlflow_data_word2vec_models_50000_v1_*.csv`
- Courbes d'entra√Ænement : Disponibles dans MLflow artifacts (training_curves/)
- MLflow UI : http://localhost:5001 (exp√©rience: `word2vec_models_50000_v1`)

---

### Surveillance en production
- **Seuil d'alerte** : 3 pr√©dictions incorrectes en 5 minutes
- **Monitoring** : AWS CloudWatch
- **Alertes** : Email/SMS automatiques
- **Drift detection** : Surveillance de la qualit√© des pr√©dictions

## Contribution

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -m 'Ajout nouvelle fonctionnalit√©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Cr√©er une Pull Request

## License

Ce projet est d√©velopp√© dans le cadre de la formation OpenClassrooms AI Engineer.

## Support

Pour toute question ou probl√®me :
1. Consulter la documentation dans `/docs`
2. V√©rifier les issues existantes
3. Cr√©er une nouvelle issue avec le template appropri√©

---

**Statut du projet** : En d√©veloppement actif
**Derni√®re mise √† jour** : Voir les commits r√©cents
