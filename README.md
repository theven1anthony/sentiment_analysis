# Analyse de Sentiments pour Air Paradis

Projet d'analyse de sentiment sur des tweets pour anticiper les potentiels bad buzz sur les r√©seaux sociaux. Ce projet impl√©mente trois approches de machine learning (mod√®le simple, mod√®le avanc√© TensorFlow/Keras, et BERT) avec une infrastructure MLOps compl√®te.

## Table des Mati√®res

- [Installation](#installation)
- [Configuration](#configuration)
- [Donn√©es](#donn√©es)
- [Utilisation](#utilisation)
  - [Entra√Ænement des mod√®les](#entra√Ænement-des-mod√®les)
  - [Interface MLflow](#interface-mlflow)
  - [API de pr√©diction](#api-de-pr√©diction)
- [Architecture](#architecture)
- [Tests](#tests)
- [D√©ploiement](#d√©ploiement)

## Installation

### Pr√©requis
- Python 3.12+
- Git
- Au moins 4GB de RAM pour les mod√®les BERT

### Installation rapide
```bash
# Cloner le projet
git clone <url-du-projet>
cd sentiment_analysis

# Cr√©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# ou
venv\Scripts\activate     # Sur Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

## Configuration

### 1. Donn√©es
Placez le dataset Sentiment140 dans le dossier `data/` :
```
data/
‚îú‚îÄ‚îÄ training.1600000.processed.noemoticon.csv  # Dataset principal
‚îî‚îÄ‚îÄ raw/                                       # Autres donn√©es brutes
```

### 2. MLflow
D√©marrez le serveur de tracking MLflow :
```bash
mlflow ui --host 0.0.0.0 --port 5001
```
Interface accessible sur : http://localhost:5001

## Donn√©es

Le projet utilise le dataset **Sentiment140** contenant 1,6M de tweets √©tiquet√©s :
- **0** : Sentiment n√©gatif
- **1** : Sentiment positif
- **Format** : CSV avec colonnes [sentiment, id, date, query, user, text]
- **R√©partition** : 50% n√©gatif, 50% positif (√©quilibr√©)

## Utilisation

### Entra√Ænement des mod√®les

#### Mod√®le Simple (Baseline)

**Entra√Æner avec une technique sp√©cifique :**
```bash
# Avec stemming
python train_simple_model.py --technique=stemming --description="Baseline stemming production"

# Avec lemmatization
python train_simple_model.py --technique=lemmatization --description="Baseline lemmatization"
```

**Comparer les techniques :**
```bash
# Comparaison compl√®te stemming vs lemmatization
python train_simple_model.py --technique=both --description="Comparaison techniques preprocessing"
```

**Options avanc√©es :**
```bash
# Avec √©chantillon r√©duit pour test rapide
python train_simple_model.py \
    --technique=lemmatization \
    --sample-size=50000 \
    --description="Test rapide lemmatization" \
    --experiment-name="tests_rapides"

# Dataset complet (par d√©faut)
python train_simple_model.py --technique=both --description="Entra√Ænement production"
```

#### Mod√®les Avanc√©s (TensorFlow/Keras)
```bash
# √Ä impl√©menter - mod√®les avec embeddings Word2Vec/FastText
python train_advanced_model.py --embedding=word2vec
python train_advanced_model.py --embedding=fasttext --with-lstm
```

#### Mod√®le BERT
```bash
# √Ä impl√©menter - mod√®le BERT
python train_bert_model.py --model=bert-base-uncased
```

### Interface MLflow

1. **D√©marrer MLflow UI :**
   ```bash
   mlflow ui --host 0.0.0.0 --port 5001
   ```

2. **Naviguer dans l'interface :**
   - **Exp√©rimentations** : Organis√©es par type de mod√®le
   - **Runs** : Chaque entra√Ænement avec ses m√©triques
   - **Mod√®les** : Registre centralis√© des mod√®les
   - **Comparaison** : Comparer les performances visuellement

3. **Tags et filtres disponibles :**
   - `preprocessing_technique` : stemming, lemmatization
   - `model_category` : baseline, advanced, bert
   - `algorithm` : logistic_regression, lstm, bert
   - `description` : Description personnalis√©e

### API de pr√©diction

#### D√©marrer l'API locale
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Utiliser l'API
```bash
# Pr√©diction simple
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this product!"}'

# R√©ponse
{
  "sentiment": 1,
  "confidence": 0.87,
  "text": "I love this product!"
}
```

#### Interface de test Streamlit
```bash
streamlit run interface/app.py
```

## Architecture

### Structure du projet
```
sentiment_analysis/
‚îú‚îÄ‚îÄ api/                    # API FastAPI
‚îú‚îÄ‚îÄ data/                   # Datasets
‚îú‚îÄ‚îÄ models/                 # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ staging/           # Mod√®les en test
‚îÇ   ‚îî‚îÄ‚îÄ production/        # Mod√®les d√©ploy√©s
‚îú‚îÄ‚îÄ notebooks/             # Exploration de donn√©es
‚îú‚îÄ‚îÄ reports/               # Rapports d'√©valuation
‚îú‚îÄ‚îÄ src/                   # Code source
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/        # Impl√©mentations d'embeddings
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/        # M√©triques d'√©valuation
‚îÇ   ‚îú‚îÄ‚îÄ models/            # D√©finitions des mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/        # Outils de surveillance
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing/     # Pr√©traitement des donn√©es
‚îú‚îÄ‚îÄ tests/                 # Tests unitaires
‚îî‚îÄ‚îÄ mlruns/               # Donn√©es MLflow
```

### Pipeline MLOps
1. **D√©veloppement** : Notebooks d'exploration
2. **Entra√Ænement** : Scripts param√©tr√©s avec MLflow
3. **√âvaluation** : M√©triques automatiques et rapports
4. **Registre** : Mod√®les versionn√©s dans MLflow
5. **D√©ploiement** : API FastAPI sur cloud
6. **Surveillance** : Monitoring en production

## Tests

```bash
# Tests unitaires
python -m pytest tests/ -v

# Tests avec couverture
python -m pytest tests/ -v --cov=src --cov-report=html

# Tests de qualit√© de code
black src/ tests/ api/      # Formatage
flake8 src/ tests/ api/     # Linting
mypy src/ api/              # V√©rification de types
```

## D√©ploiement

### D√©ploiement local
```bash
# API en mode production
uvicorn api.main:app --host 0.0.0.0 --port 8000

# Avec Docker (√† configurer)
docker build -t sentiment-api .
docker run -p 8000:8000 sentiment-api
```

### D√©ploiement cloud (AWS)
```bash
# Configuration √† venir
# - AWS EC2 ou Lambda
# - Pipeline CI/CD avec GitHub Actions
# - Monitoring CloudWatch
```

## M√©triques et Monitoring

### M√©triques d'√©valuation
- **Accuracy** : Taux de bonnes classifications
- **F1-Score** : Mesure √©quilibr√©e (m√©trique principale)
- **Pr√©cision/Rappel** : Performance par classe
- **AUC-ROC** : Capacit√© de discrimination
- **Temps d'entra√Ænement** : Performance op√©rationnelle

## R√©sultats des Exp√©rimentations

### üìä Analyse Comparative des Techniques de Pr√©traitement

**Exp√©rimentation** : `simple_models_v4` - Impact de la gestion des n√©gations et √©motions

#### üèÜ Classement des Configurations

| Rang | Configuration | Technique Gagnante | F1-Score | Accuracy | Temps (s) |
|------|---------------|-------------------|----------|----------|-----------|
| ü•á | N√©gations=True, √âmotions=True | **STEMMING** | **0.7994** | **0.7994** | 15.88 |
| ü•à | N√©gations=True, √âmotions=False | **LEMMATIZATION** | **0.7992** | **0.7992** | 16.72 |
| ü•â | N√©gations=False, √âmotions=True | **STEMMING** | **0.7978** | **0.7978** | 15.38 |
| 4Ô∏è‚É£ | N√©gations=False, √âmotions=False | **STEMMING** | **0.7966** | **0.7967** | 14.25 |

#### üìà Analyse des Tendances

**Impact des n√©gations :**
- ‚úÖ **Am√©lioration** : +0.21% en F1-Score
- La gestion intelligente des n√©gations apporte un gain mesurable

**Impact des √©motions :**
- ‚úÖ **L√©g√®re am√©lioration** : +0.03% en F1-Score
- Impact minimal mais positif sur les performances

**Technique pr√©f√©r√©e :**
- **Stemming** : F1 moyen = 0.7982 (meilleur)
- **Lemmatization** : F1 moyen = 0.7978
- Stemming l√©g√®rement sup√©rieur en moyenne

#### üí° Conclusions

1. **Configuration optimale** : N√©gations=True + √âmotions=True + Stemming
2. **Gestion des n√©gations** : Impact plus important que la pr√©servation des √©motions
3. **Stabilit√©** : R√©sultats coh√©rents entre les configurations
4. **Gains marginaux** : Diff√©rences faibles (~0.3%) mais mesurables
5. **Recommendation** : Utiliser la configuration compl√®te pour la production

### Surveillance en production
- **Seuil d'alerte** : 3 pr√©dictions incorrectes en 5 minutes
- **Monitoring** : AWS CloudWatch
- **Alertes** : Email/SMS automatiques
- **Drift detection** : Surveillance de la qualit√© des pr√©dictions

## Contribution

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Commit (`git commit -m 'Ajout nouvelle fonctionnalit√©'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Cr√©er une Pull Request

## License

Ce projet est d√©velopp√© dans le cadre de la formation OpenClassrooms AI Engineer.

## Support

Pour toute question ou probl√®me :
1. Consulter la documentation dans `/docs`
2. V√©rifier les issues existantes
3. Cr√©er une nouvelle issue avec le template appropri√©

---

**Statut du projet** : En d√©veloppement actif
**Derni√®re mise √† jour** : Voir les commits r√©cents
